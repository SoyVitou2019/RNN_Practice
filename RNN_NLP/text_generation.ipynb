{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Text Generation\n",
    "This notebook explains how we can split a given corpus of data info features and labels and then train a neural network to predict the next word in a sentence\n",
    "\n",
    "1. Create a corpus - break the text down to list of sentences.\n",
    "2. Create a word_index(vocabulary) from the text.\n",
    "3. Tokenize the data and create n-GRAM sequence for each sequence of the corpus\n",
    "4. Pad those sequences.\n",
    "5. Segregate features from the sequences by reserving the last element of the array as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\soyvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soyvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "## import the required libraries and APIs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ince we set return_sequences=True in the LSTM layers, the output is now a three-dimension vector. If we input that into the Dense layer, it will raise an error because the Dense layer only accepts two-dimension input. In order to input a three-dimension vector, we need to use a wrapper layer called TimeDistributed. This layer will help us maintain output’s shape, so that we can achieve a sequence as output in the end.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ince we set return_sequences=true in the lstm layers, the output is now a three-dimension vector', ' if we input that into the dense layer, it will raise an error because the dense layer only accepts two-dimension input', ' in order to input a three-dimension vector, we need to use a wrapper layer called timedistributed', ' this layer will help us maintain output’s shape, so that we can achieve a sequence as output in the end', '']\n"
     ]
    }
   ],
   "source": [
    "## instantiate tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "## create corpus by lowering the letters and splitting the text by \\n\n",
    "corpus = data.lower().split(\".\")\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train the tokenizer and create word encoding dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'we': 2, 'a': 3, 'layer': 4, 'in': 5, 'dimension': 6, 'input': 7, 'output': 8, 'three': 9, 'vector': 10, 'that': 11, 'dense': 12, 'will': 13, 'to': 14, 'ince': 15, 'set': 16, 'return': 17, 'sequences': 18, 'true': 19, 'lstm': 20, 'layers': 21, 'is': 22, 'now': 23, 'if': 24, 'into': 25, 'it': 26, 'raise': 27, 'an': 28, 'error': 29, 'because': 30, 'only': 31, 'accepts': 32, 'two': 33, 'order': 34, 'need': 35, 'use': 36, 'wrapper': 37, 'called': 38, 'timedistributed': 39, 'this': 40, 'help': 41, 'us': 42, 'maintain': 43, 'output’s': 44, 'shape': 45, 'so': 46, 'can': 47, 'achieve': 48, 'sequence': 49, 'as': 50, 'end': 51}\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# calculate vocabulary size + 1 for <oov> token\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22, 23, 3, 9, 6, 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([corpus[0]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create N-gram sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create n-gram sequences of each text sequence\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0] # get all the tokens of the sequence\n",
    "    for i in range(1, len(tokens)): # create n-gram sequences\n",
    "        n_gram_sequence = tokens[: i+ 1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15, 2], [15, 2, 16], [15, 2, 16, 17], [15, 2, 16, 17, 18], [15, 2, 16, 17, 18, 19], [15, 2, 16, 17, 18, 19, 5], [15, 2, 16, 17, 18, 19, 5, 1], [15, 2, 16, 17, 18, 19, 5, 1, 20], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22, 23], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22, 23, 3], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22, 23, 3, 9], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22, 23, 3, 9, 6], [15, 2, 16, 17, 18, 19, 5, 1, 20, 21, 1, 8, 22, 23, 3, 9, 6, 10], [24, 2], [24, 2, 7], [24, 2, 7, 11], [24, 2, 7, 11, 25], [24, 2, 7, 11, 25, 1], [24, 2, 7, 11, 25, 1, 12], [24, 2, 7, 11, 25, 1, 12, 4], [24, 2, 7, 11, 25, 1, 12, 4, 26], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12, 4], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12, 4, 31], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12, 4, 31, 32], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12, 4, 31, 32, 33], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12, 4, 31, 32, 33, 6], [24, 2, 7, 11, 25, 1, 12, 4, 26, 13, 27, 28, 29, 30, 1, 12, 4, 31, 32, 33, 6, 7], [5, 34], [5, 34, 14], [5, 34, 14, 7], [5, 34, 14, 7, 3], [5, 34, 14, 7, 3, 9], [5, 34, 14, 7, 3, 9, 6], [5, 34, 14, 7, 3, 9, 6, 10], [5, 34, 14, 7, 3, 9, 6, 10, 2], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14, 36], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14, 36, 3], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14, 36, 3, 37], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14, 36, 3, 37, 4], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14, 36, 3, 37, 4, 38], [5, 34, 14, 7, 3, 9, 6, 10, 2, 35, 14, 36, 3, 37, 4, 38, 39], [40, 4], [40, 4, 13], [40, 4, 13, 41], [40, 4, 13, 41, 42], [40, 4, 13, 41, 42, 43], [40, 4, 13, 41, 42, 43, 44], [40, 4, 13, 41, 42, 43, 44, 45], [40, 4, 13, 41, 42, 43, 44, 45, 46], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3, 49], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3, 49, 50], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3, 49, 50, 8], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3, 49, 50, 8, 5], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3, 49, 50, 8, 5, 1], [40, 4, 13, 41, 42, 43, 44, 45, 46, 11, 2, 47, 48, 3, 49, 50, 8, 5, 1, 51]]\n"
     ]
    }
   ],
   "source": [
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pad sequences\n",
    "max_seq_array = max([len(i) for i in input_sequences])\n",
    "input_seq_array = np.array(pad_sequences(input_sequences, maxlen=max_seq_array, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0, 15,  2],\n",
       "       [ 0,  0,  0, ..., 15,  2, 16],\n",
       "       [ 0,  0,  0, ...,  2, 16, 17],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 50,  8,  5],\n",
       "       [ 0,  0,  0, ...,  8,  5,  1],\n",
       "       [ 0,  0, 40, ...,  5,  1, 51]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Extract features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0 15]\n",
      " [ 0  0  0 ...  0 15  2]\n",
      " [ 0  0  0 ... 15  2 16]\n",
      " ...\n",
      " [ 0  0  0 ... 49 50  8]\n",
      " [ 0  0  0 ... 50  8  5]\n",
      " [ 0  0 40 ...  8  5  1]] [ 2 16 17 18 19  5  1 20 21  1  8 22 23  3  9  6 10  2  7 11 25  1 12  4\n",
      " 26 13 27 28 29 30  1 12  4 31 32 33  6  7 34 14  7  3  9  6 10  2 35 14\n",
      " 36  3 37  4 38 39  4 13 41 42 43 44 45 46 11  2 47 48  3 49 50  8  5  1\n",
      " 51]\n"
     ]
    }
   ],
   "source": [
    "# creating features(x) and label(y)\n",
    "x = input_seq_array[:, :-1]\n",
    "labels = input_seq_array[:, -1]\n",
    "print(x, labels)\n",
    "# one-hot encode the labels to get y\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'we': 2, 'a': 3, 'layer': 4, 'in': 5, 'dimension': 6, 'input': 7, 'output': 8, 'three': 9, 'vector': 10, 'that': 11, 'dense': 12, 'will': 13, 'to': 14, 'ince': 15, 'set': 16, 'return': 17, 'sequences': 18, 'true': 19, 'lstm': 20, 'layers': 21, 'is': 22, 'now': 23, 'if': 24, 'into': 25, 'it': 26, 'raise': 27, 'an': 28, 'error': 29, 'because': 30, 'only': 31, 'accepts': 32, 'two': 33, 'order': 34, 'need': 35, 'use': 36, 'wrapper': 37, 'called': 38, 'timedistributed': 39, 'this': 40, 'help': 41, 'us': 42, 'maintain': 43, 'output’s': 44, 'shape': 45, 'so': 46, 'can': 47, 'achieve': 48, 'sequence': 49, 'as': 50, 'end': 51}\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  2 16]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)\n",
    "print(x[2])\n",
    "print(y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\soyvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\soyvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From c:\\Users\\soyvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\soyvi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 16s 74ms/step - loss: 3.9507 - accuracy: 0.0274\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3.9402 - accuracy: 0.0548\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 3.9317 - accuracy: 0.0548\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.9223 - accuracy: 0.0548\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.9118 - accuracy: 0.0548\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.9002 - accuracy: 0.0548\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8863 - accuracy: 0.0548\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.8670 - accuracy: 0.0548\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8465 - accuracy: 0.0548\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.8188 - accuracy: 0.0548\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.7880 - accuracy: 0.0548\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.7717 - accuracy: 0.0548\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.7538 - accuracy: 0.0548\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.7411 - accuracy: 0.0548\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 3.7231 - accuracy: 0.0548\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.7038 - accuracy: 0.0548\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3.6869 - accuracy: 0.0548\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.6731 - accuracy: 0.0822\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.6598 - accuracy: 0.1096\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.6423 - accuracy: 0.1233\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.6261 - accuracy: 0.1644\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.6101 - accuracy: 0.1370\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3.5902 - accuracy: 0.1370\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.5692 - accuracy: 0.1370\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.5438 - accuracy: 0.1370\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.5237 - accuracy: 0.1370\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3.4941 - accuracy: 0.1644\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.4681 - accuracy: 0.1507\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.4333 - accuracy: 0.1644\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.4033 - accuracy: 0.1644\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 3.3725 - accuracy: 0.1644\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.3323 - accuracy: 0.1644\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 3.3000 - accuracy: 0.1644\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 3.2585 - accuracy: 0.1644\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.2222 - accuracy: 0.1370\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.1850 - accuracy: 0.1370\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 3.1399 - accuracy: 0.1507\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.1061 - accuracy: 0.1507\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.0734 - accuracy: 0.1507\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.0314 - accuracy: 0.1507\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.9980 - accuracy: 0.1507\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 2.9569 - accuracy: 0.1507\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.9206 - accuracy: 0.1507\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.9246 - accuracy: 0.1644\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.9161 - accuracy: 0.1644\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.8588 - accuracy: 0.1918\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.8102 - accuracy: 0.1918\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7661 - accuracy: 0.2055\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.7336 - accuracy: 0.2192\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.6967 - accuracy: 0.2192\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.6561 - accuracy: 0.2603\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.6237 - accuracy: 0.2466\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2.5968 - accuracy: 0.2466\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 2.5704 - accuracy: 0.2466\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2.5350 - accuracy: 0.2603\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 2.4995 - accuracy: 0.2740\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.4849 - accuracy: 0.2740\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2.4481 - accuracy: 0.2329\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.4212 - accuracy: 0.3014\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.4042 - accuracy: 0.2466\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3612 - accuracy: 0.2877\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2.3482 - accuracy: 0.2877\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.3207 - accuracy: 0.2740\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.2917 - accuracy: 0.2877\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.2626 - accuracy: 0.3425\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.2493 - accuracy: 0.3562\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2193 - accuracy: 0.3014\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1927 - accuracy: 0.3562\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.1785 - accuracy: 0.3562\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2.1504 - accuracy: 0.3562\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 2.1270 - accuracy: 0.3562\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.0971 - accuracy: 0.3699\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0743 - accuracy: 0.3973\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0425 - accuracy: 0.3973\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0438 - accuracy: 0.4110\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0182 - accuracy: 0.4247\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2.0131 - accuracy: 0.3973\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9884 - accuracy: 0.4247\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.9463 - accuracy: 0.4384\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.9290 - accuracy: 0.4932\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 1.8962 - accuracy: 0.5068\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.8764 - accuracy: 0.5068\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 1.8514 - accuracy: 0.5068\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.8403 - accuracy: 0.4932\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.8115 - accuracy: 0.5616\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.7995 - accuracy: 0.5753\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7750 - accuracy: 0.5890\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7642 - accuracy: 0.6027\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.7412 - accuracy: 0.6575\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7178 - accuracy: 0.6438\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.6982 - accuracy: 0.6438\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.6882 - accuracy: 0.6027\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.6594 - accuracy: 0.6164\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.6463 - accuracy: 0.6164\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 1.6379 - accuracy: 0.6301\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.6105 - accuracy: 0.6164\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.6413 - accuracy: 0.6027\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6228 - accuracy: 0.5890\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.5791 - accuracy: 0.6164\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.5551 - accuracy: 0.6164\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5428 - accuracy: 0.6164\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5264 - accuracy: 0.6301\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4968 - accuracy: 0.6575\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.4905 - accuracy: 0.6438\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.4713 - accuracy: 0.6712\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.4664 - accuracy: 0.6712\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.4506 - accuracy: 0.6712\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.4380 - accuracy: 0.7123\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.4214 - accuracy: 0.7534\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.4152 - accuracy: 0.7534\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4022 - accuracy: 0.7260\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3954 - accuracy: 0.7260\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.3814 - accuracy: 0.7671\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3491 - accuracy: 0.7808\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3552 - accuracy: 0.7671\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3288 - accuracy: 0.7808\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3098 - accuracy: 0.7808\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3122 - accuracy: 0.7397\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.2864 - accuracy: 0.7397\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.2727 - accuracy: 0.7945\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.2676 - accuracy: 0.7808\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2511 - accuracy: 0.7671\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2361 - accuracy: 0.8082\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.2250 - accuracy: 0.7945\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2084 - accuracy: 0.7945\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.2050 - accuracy: 0.8082\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.1945 - accuracy: 0.7945\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.1916 - accuracy: 0.7945\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1729 - accuracy: 0.8082\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.1725 - accuracy: 0.8219\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.1495 - accuracy: 0.8219\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.1397 - accuracy: 0.8082\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 1.1283 - accuracy: 0.8493\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.1181 - accuracy: 0.8630\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1133 - accuracy: 0.8630\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0998 - accuracy: 0.8767\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 1.0860 - accuracy: 0.8630\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.0804 - accuracy: 0.8767\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0738 - accuracy: 0.8356\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0601 - accuracy: 0.8493\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0537 - accuracy: 0.8493\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 1.0398 - accuracy: 0.8493\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0306 - accuracy: 0.8493\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0165 - accuracy: 0.8630\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.0071 - accuracy: 0.8767\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9984 - accuracy: 0.8904\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9925 - accuracy: 0.8904\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9877 - accuracy: 0.9041\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9984 - accuracy: 0.9041\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9919 - accuracy: 0.8767\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9832 - accuracy: 0.9041\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9610 - accuracy: 0.9041\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9633 - accuracy: 0.8904\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9496 - accuracy: 0.9041\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9404 - accuracy: 0.8904\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9274 - accuracy: 0.8767\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9193 - accuracy: 0.8630\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9079 - accuracy: 0.9178\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9012 - accuracy: 0.9315\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8890 - accuracy: 0.9178\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8781 - accuracy: 0.9178\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8699 - accuracy: 0.9041\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8615 - accuracy: 0.9178\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8548 - accuracy: 0.9178\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.8470 - accuracy: 0.9178\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8385 - accuracy: 0.9178\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8284 - accuracy: 0.9178\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8226 - accuracy: 0.9178\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8109 - accuracy: 0.9178\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.8066 - accuracy: 0.9315\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.8000 - accuracy: 0.9315\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7927 - accuracy: 0.9315\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7876 - accuracy: 0.9315\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7787 - accuracy: 0.9589\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7724 - accuracy: 0.9452\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7626 - accuracy: 0.9452\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7540 - accuracy: 0.9863\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7606 - accuracy: 0.9726\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7440 - accuracy: 0.9589\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.7339 - accuracy: 0.9589\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7242 - accuracy: 0.9726\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7165 - accuracy: 0.9863\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7039 - accuracy: 0.9589\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7097 - accuracy: 0.9589\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6929 - accuracy: 0.9726\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6951 - accuracy: 0.9589\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6869 - accuracy: 0.9589\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6785 - accuracy: 0.9726\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.6733 - accuracy: 0.9589\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6656 - accuracy: 0.9452\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6592 - accuracy: 0.9452\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6529 - accuracy: 0.9726\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6485 - accuracy: 0.9589\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6402 - accuracy: 0.9726\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6317 - accuracy: 0.9726\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6228 - accuracy: 0.9726\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6153 - accuracy: 0.9726\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6083 - accuracy: 0.9726\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.6118 - accuracy: 0.9726\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6059 - accuracy: 0.9726\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6297 - accuracy: 0.9452\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6203 - accuracy: 0.9589\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6184 - accuracy: 0.9452\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6021 - accuracy: 0.9589\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5929 - accuracy: 0.9726\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5825 - accuracy: 0.9726\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5698 - accuracy: 0.9726\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5651 - accuracy: 0.9726\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5572 - accuracy: 0.9726\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5590 - accuracy: 0.9726\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5520 - accuracy: 0.9726\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5446 - accuracy: 0.9726\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5344 - accuracy: 0.9726\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5309 - accuracy: 0.9726\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5249 - accuracy: 0.9726\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5217 - accuracy: 0.9726\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5122 - accuracy: 0.9726\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5094 - accuracy: 0.9726\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5050 - accuracy: 0.9726\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4960 - accuracy: 0.9726\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4938 - accuracy: 0.9726\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4912 - accuracy: 0.9726\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4862 - accuracy: 0.9726\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4819 - accuracy: 0.9726\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4789 - accuracy: 0.9726\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4717 - accuracy: 0.9726\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4618 - accuracy: 0.9726\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.4552 - accuracy: 0.9726\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.4516 - accuracy: 0.9726\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.4465 - accuracy: 0.9726\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4412 - accuracy: 0.9726\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4368 - accuracy: 0.9726\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4336 - accuracy: 0.9726\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4287 - accuracy: 0.9726\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4252 - accuracy: 0.9726\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4237 - accuracy: 0.9726\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4174 - accuracy: 0.9726\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4151 - accuracy: 0.9726\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4125 - accuracy: 0.9726\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4098 - accuracy: 0.9726\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4058 - accuracy: 0.9863\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4005 - accuracy: 0.9863\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3977 - accuracy: 0.9863\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3937 - accuracy: 0.9863\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3908 - accuracy: 0.9726\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3898 - accuracy: 0.9726\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3853 - accuracy: 0.9726\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3934 - accuracy: 0.9726\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3807 - accuracy: 0.9726\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3880 - accuracy: 0.9726\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3842 - accuracy: 0.9726\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3686 - accuracy: 0.9863\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3662 - accuracy: 0.9863\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3716 - accuracy: 0.9863\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3602 - accuracy: 0.9863\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3564 - accuracy: 0.9863\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3564 - accuracy: 0.9863\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3528 - accuracy: 0.9863\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3502 - accuracy: 0.9726\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3488 - accuracy: 0.9726\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3430 - accuracy: 0.9726\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.3369 - accuracy: 0.9726\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3318 - accuracy: 0.9863\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3313 - accuracy: 0.9863\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3277 - accuracy: 0.9863\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3252 - accuracy: 0.9863\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3212 - accuracy: 0.9863\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3179 - accuracy: 0.9863\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3163 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3154 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3099 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3066 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3049 - accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3023 - accuracy: 0.9863\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3000 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2967 - accuracy: 0.9863\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2936 - accuracy: 0.9863\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2907 - accuracy: 0.9863\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2889 - accuracy: 0.9863\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2869 - accuracy: 0.9863\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2863 - accuracy: 0.9726\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2826 - accuracy: 0.9726\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2794 - accuracy: 0.9726\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2778 - accuracy: 0.9863\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2765 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2754 - accuracy: 0.9863\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2709 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2688 - accuracy: 0.9863\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.2702 - accuracy: 0.9863\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.2655 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.2617 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2632 - accuracy: 0.9863\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2603 - accuracy: 0.9863\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2571 - accuracy: 0.9863\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2554 - accuracy: 0.9863\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2530 - accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2509 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2492 - accuracy: 0.9863\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2473 - accuracy: 0.9863\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2448 - accuracy: 0.9863\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2418 - accuracy: 0.9863\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2405 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2375 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2358 - accuracy: 0.9863\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2358 - accuracy: 0.9863\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2325 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2300 - accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2292 - accuracy: 0.9863\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2270 - accuracy: 0.9863\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2245 - accuracy: 0.9863\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2229 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2206 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2189 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.2170 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2152 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.2130 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2122 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.2102 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2076 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2045 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2037 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2012 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1998 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2015 - accuracy: 0.9863\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1997 - accuracy: 0.9863\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1959 - accuracy: 0.9863\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1928 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1967 - accuracy: 0.9863\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1948 - accuracy: 0.9863\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1915 - accuracy: 0.9863\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1907 - accuracy: 0.9863\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1888 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1869 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1844 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1820 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1807 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1798 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1784 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1774 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1754 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1754 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1734 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1713 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1696 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1704 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1694 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1672 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1649 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1637 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1627 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1614 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1601 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1601 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1593 - accuracy: 0.9863\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1574 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1566 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1557 - accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1540 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1529 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1524 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1508 - accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1498 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1487 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1474 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1465 - accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1455 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1452 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1441 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1423 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1411 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1404 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1395 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1386 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1378 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1369 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1360 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1352 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1352 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1344 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1325 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1318 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1312 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1299 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1277 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1272 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1263 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1256 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1243 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1242 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1247 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1241 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1212 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1208 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1211 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1210 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1174 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1164 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1153 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1130 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1131 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.1121 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1109 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1101 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1097 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1089 - accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1082 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1068 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1059 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1056 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1046 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1038 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1030 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1030 - accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1029 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1012 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1005 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0998 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0997 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0983 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0979 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0970 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0957 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0951 - accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0946 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0937 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0932 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0929 - accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0925 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0917 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0910 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0908 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0900 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0895 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0881 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0873 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0868 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0857 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0852 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0849 - accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0842 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0835 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0830 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0824 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0818 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0814 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0810 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0807 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0801 - accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0796 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0789 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0785 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0779 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0773 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0769 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0765 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0757 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0744 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0739 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0730 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0726 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0721 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0709 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0705 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0705 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0703 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0698 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0691 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0681 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0678 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0670 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0661 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0658 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0656 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0649 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0646 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0642 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0638 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0633 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 64, input_length = max_seq_array - 1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "history = model.fit(x, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(history=history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'we': 2, 'a': 3, 'layer': 4, 'in': 5, 'dimension': 6, 'input': 7, 'output': 8, 'three': 9, 'vector': 10, 'that': 11, 'dense': 12, 'will': 13, 'to': 14, 'ince': 15, 'set': 16, 'return': 17, 'sequences': 18, 'true': 19, 'lstm': 20, 'layers': 21, 'is': 22, 'now': 23, 'if': 24, 'into': 25, 'it': 26, 'raise': 27, 'an': 28, 'error': 29, 'because': 30, 'only': 31, 'accepts': 32, 'two': 33, 'order': 34, 'need': 35, 'use': 36, 'wrapper': 37, 'called': 38, 'timedistributed': 39, 'this': 40, 'help': 41, 'us': 42, 'maintain': 43, 'output’s': 44, 'shape': 45, 'so': 46, 'can': 47, 'achieve': 48, 'sequence': 49, 'as': 50, 'end': 51}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9079362 [7]\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"It was a cold night\"\n",
    "\n",
    "tokenlist = tokenizer.texts_to_sequences([seed_text])\n",
    "token_pad = pad_sequences(tokenlist, maxlen=max_seq_array - 1, padding='pre')\n",
    "predictd = model.predict(token_pad, verbose=0)\n",
    "print(np.max(predictd), np.argmax(predictd, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ince we set return_sequences=True in the LSTM layers, the output is now a three-dimension vector. If we input that into the Dense layer, it will raise an error because the Dense layer only accepts two-dimension input. In order to input a three-dimension vector, we need to use a wrapper layer called TimeDistributed. This layer will help us maintain output’s shape, so that we can achieve a sequence as output in the end.\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  7]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  7  7]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  7  7  3]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  7  7  3  9]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  7  7  3  9  6]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  7  7  3  9  6 10]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0 20  7  7  3  9  6 10  2]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0 20  7  7  3  9  6 10  2 35]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0 20  7  7  3  9  6 10  2 35 14]]\n",
      "[[ 0  0  0  0  0  0  0  0  0  0 20  7  7  3  9  6 10  2 35 14 36]]\n",
      "[[ 0  0  0  0  0  0  0  0  0 20  7  7  3  9  6 10  2 35 14 36  3]]\n",
      "[[ 0  0  0  0  0  0  0  0 20  7  7  3  9  6 10  2 35 14 36  3 37]]\n",
      "[[ 0  0  0  0  0  0  0 20  7  7  3  9  6 10  2 35 14 36  3 37  4]]\n",
      "[[ 0  0  0  0  0  0 20  7  7  3  9  6 10  2 35 14 36  3 37  4 38]]\n",
      "[[ 0  0  0  0  0 20  7  7  3  9  6 10  2 35 14 36  3 37  4 38 39]]\n",
      "[[ 0  0  0  0 20  7  7  3  9  6 10  2 35 14 36  3 37  4 38 39 39]]\n",
      "[[ 0  0  0 20  7  7  3  9  6 10  2 35 14 36  3 37  4 38 39 39 39]]\n",
      "[[ 0  0 20  7  7  3  9  6 10  2 35 14 36  3 37  4 38 39 39 39 39]]\n",
      "[[ 0 20  7  7  3  9  6 10  2 35 14 36  3 37  4 38 39 39 39 39 39]]\n",
      "lstm input input a three dimension vector we need to use a wrapper layer called timedistributed timedistributed timedistributed timedistributed timedistributed timedistributed\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"lstm\"\n",
    "\n",
    "## add number of words you want to predict\n",
    "next_words = 20\n",
    "\n",
    "## run the loop to predict and concatenate the word\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_seq_array - 1, padding='pre')\n",
    "    print(token_list)\n",
    "    # predict the class using the trained model\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    higest_prediction = np.argmax(predicted)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        # reference the predicted class with the vocabulary\n",
    "        if index == higest_prediction:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
